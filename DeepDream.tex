
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{DeepDream}
    
    
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{deepdream}{%
\section{DeepDream}\label{deepdream}}

by Kathirvel Gounder

    \hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

I wrote this interactive python notebook for two purposes, one as a
tensorflow tutorial and one as a interactive exploration of feature maps
for my peers. I encourage everyone to read my literature survey as it
contains valuable information and intuition regarding neural methods in
modern art. I definitiely think the information and references available
in the paper are more important and enlightening than this python
notebook. Anyways what we will be doing in this activity is basically
modifying input images to elicit certain responses from the network. The
modified inputs, as you will see, are very psychedelic in nature. This
is further indication that our visual system is somewhat similar to a
convolutional architecture albeit at a very high level. The idea is
pretty simple but there are some computational tricks and hurdles that
we have to encounter to not run out of memory and maintain image
resolution. We also have to write some boilerplate code to handle
downloaded models and images. Lets Go !

    \hypertarget{set-up}{%
\section{Set Up}\label{set-up}}

There is quite a lot of set up that we have to do. First if you are
trying to run this notebook in the google colab environment make sure to
upload all the images associated with the notebook aswell. Otherwise you
will run into errors. Just click the ``files'' button next to ``code
snippets'' and hit upload. The following helper functions are for
downloading the pretrained inception model from the internet. Feel free
to skip this section as it really doesn't pertain to the main concepts
but is essential for the proper functioning of the code.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k+kn}{import} \PY{n+nn}{sys}
        \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{urllib}\PY{n+nn}{.}\PY{n+nn}{request}
        \PY{k+kn}{import} \PY{n+nn}{tarfile}
        \PY{k+kn}{import} \PY{n+nn}{zipfile}
        
        \PY{k}{def} \PY{n+nf}{\PYZus{}print\PYZus{}download\PYZus{}progress}\PY{p}{(}\PY{n}{count}\PY{p}{,} \PY{n}{block\PYZus{}size}\PY{p}{,} \PY{n}{total\PYZus{}size}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Function used for printing the download progress.}
        \PY{l+s+sd}{    Used as a call\PYZhy{}back function in maybe\PYZus{}download\PYZus{}and\PYZus{}extract().}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Percentage completion.}
            \PY{n}{pct\PYZus{}complete} \PY{o}{=} \PY{n+nb}{float}\PY{p}{(}\PY{n}{count} \PY{o}{*} \PY{n}{block\PYZus{}size}\PY{p}{)} \PY{o}{/} \PY{n}{total\PYZus{}size}
        
            \PY{c+c1}{\PYZsh{} Limit it because rounding errors may cause it to exceed 100\PYZpc{}.}
            \PY{n}{pct\PYZus{}complete} \PY{o}{=} \PY{n+nb}{min}\PY{p}{(}\PY{l+m+mf}{1.0}\PY{p}{,} \PY{n}{pct\PYZus{}complete}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Status\PYZhy{}message. Note the \PYZbs{}r which means the line should overwrite itself.}
            \PY{n}{msg} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}r}\PY{l+s+s2}{\PYZhy{} Download progress: }\PY{l+s+si}{\PYZob{}0:.1\PYZpc{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{pct\PYZus{}complete}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Print it.}
            \PY{n}{sys}\PY{o}{.}\PY{n}{stdout}\PY{o}{.}\PY{n}{write}\PY{p}{(}\PY{n}{msg}\PY{p}{)}
            \PY{n}{sys}\PY{o}{.}\PY{n}{stdout}\PY{o}{.}\PY{n}{flush}\PY{p}{(}\PY{p}{)}
        
        
        \PY{k}{def} \PY{n+nf}{download}\PY{p}{(}\PY{n}{base\PYZus{}url}\PY{p}{,} \PY{n}{filename}\PY{p}{,} \PY{n}{download\PYZus{}dir}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Download the given file if it does not already exist in the download\PYZus{}dir.}
        \PY{l+s+sd}{    :param base\PYZus{}url: The internet URL without the filename.}
        \PY{l+s+sd}{    :param filename: The filename that will be added to the base\PYZus{}url.}
        \PY{l+s+sd}{    :param download\PYZus{}dir: Local directory for storing the file.}
        \PY{l+s+sd}{    :return: Nothing.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Path for local file.}
            \PY{n}{save\PYZus{}path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{download\PYZus{}dir}\PY{p}{,} \PY{n}{filename}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Check if the file already exists, otherwise we need to download it now.}
            \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{save\PYZus{}path}\PY{p}{)}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Check if the download directory exists, otherwise create it.}
                \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{download\PYZus{}dir}\PY{p}{)}\PY{p}{:}
                    \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{download\PYZus{}dir}\PY{p}{)}
        
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Downloading}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{filename}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{...}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Download the file from the internet.}
                \PY{n}{url} \PY{o}{=} \PY{n}{base\PYZus{}url} \PY{o}{+} \PY{n}{filename}
                \PY{n}{file\PYZus{}path}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{urllib}\PY{o}{.}\PY{n}{request}\PY{o}{.}\PY{n}{urlretrieve}\PY{p}{(}\PY{n}{url}\PY{o}{=}\PY{n}{url}\PY{p}{,}
                                                          \PY{n}{filename}\PY{o}{=}\PY{n}{save\PYZus{}path}\PY{p}{,}
                                                          \PY{n}{reporthook}\PY{o}{=}\PY{n}{\PYZus{}print\PYZus{}download\PYZus{}progress}\PY{p}{)}
        
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ Done!}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
        
        \PY{k}{def} \PY{n+nf}{maybe\PYZus{}download\PYZus{}and\PYZus{}extract}\PY{p}{(}\PY{n}{url}\PY{p}{,} \PY{n}{download\PYZus{}dir}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Download and extract the data if it doesn\PYZsq{}t already exist.}
        \PY{l+s+sd}{    Assumes the url is a tar\PYZhy{}ball file.}
        \PY{l+s+sd}{    :param url:}
        \PY{l+s+sd}{        Internet URL for the tar\PYZhy{}file to download.}
        \PY{l+s+sd}{        Example: \PYZdq{}https://www.cs.toronto.edu/\PYZti{}kriz/cifar\PYZhy{}10\PYZhy{}python.tar.gz\PYZdq{}}
        \PY{l+s+sd}{    :param download\PYZus{}dir:}
        \PY{l+s+sd}{        Directory where the downloaded file is saved.}
        \PY{l+s+sd}{        Example: \PYZdq{}data/CIFAR\PYZhy{}10/\PYZdq{}}
        \PY{l+s+sd}{    :return:}
        \PY{l+s+sd}{        Nothing.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Filename for saving the file downloaded from the internet.}
            \PY{c+c1}{\PYZsh{} Use the filename from the URL and add it to the download\PYZus{}dir.}
            \PY{n}{filename} \PY{o}{=} \PY{n}{url}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
            \PY{n}{file\PYZus{}path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{download\PYZus{}dir}\PY{p}{,} \PY{n}{filename}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Check if the file already exists.}
            \PY{c+c1}{\PYZsh{} If it exists then we assume it has also been extracted,}
            \PY{c+c1}{\PYZsh{} otherwise we need to download and extract it now.}
            \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{file\PYZus{}path}\PY{p}{)}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Check if the download directory exists, otherwise create it.}
                \PY{k}{if} \PY{o+ow}{not} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{exists}\PY{p}{(}\PY{n}{download\PYZus{}dir}\PY{p}{)}\PY{p}{:}
                    \PY{n}{os}\PY{o}{.}\PY{n}{makedirs}\PY{p}{(}\PY{n}{download\PYZus{}dir}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Download the file from the internet.}
                \PY{n}{file\PYZus{}path}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{urllib}\PY{o}{.}\PY{n}{request}\PY{o}{.}\PY{n}{urlretrieve}\PY{p}{(}\PY{n}{url}\PY{o}{=}\PY{n}{url}\PY{p}{,}
                                                          \PY{n}{filename}\PY{o}{=}\PY{n}{file\PYZus{}path}\PY{p}{,}
                                                          \PY{n}{reporthook}\PY{o}{=}\PY{n}{\PYZus{}print\PYZus{}download\PYZus{}progress}\PY{p}{)}
        
                \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Download finished. Extracting files.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
                \PY{k}{if} \PY{n}{file\PYZus{}path}\PY{o}{.}\PY{n}{endswith}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{.zip}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} Unpack the zip\PYZhy{}file.}
                    \PY{n}{zipfile}\PY{o}{.}\PY{n}{ZipFile}\PY{p}{(}\PY{n}{file}\PY{o}{=}\PY{n}{file\PYZus{}path}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{extractall}\PY{p}{(}\PY{n}{download\PYZus{}dir}\PY{p}{)}
                \PY{k}{elif} \PY{n}{file\PYZus{}path}\PY{o}{.}\PY{n}{endswith}\PY{p}{(}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{.tar.gz}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{.tgz}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} Unpack the tar\PYZhy{}ball.}
                    \PY{n}{tarfile}\PY{o}{.}\PY{n}{open}\PY{p}{(}\PY{n}{name}\PY{o}{=}\PY{n}{file\PYZus{}path}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r:gz}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{o}{.}\PY{n}{extractall}\PY{p}{(}\PY{n}{download\PYZus{}dir}\PY{p}{)}
        
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Done.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Data has apparently already been downloaded and unpacked.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}

    Inception Model Helper Functions

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
        
        
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        \PY{c+c1}{\PYZsh{} Various directories and file\PYZhy{}names.}
        
        \PY{c+c1}{\PYZsh{} Internet URL for the tar\PYZhy{}file with the Inception model.}
        \PY{c+c1}{\PYZsh{} Note that this might change in the future and will need to be updated.}
        \PY{n}{data\PYZus{}url} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{http://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip}\PY{l+s+s2}{\PYZdq{}}
        
        \PY{c+c1}{\PYZsh{} Directory to store the downloaded data.}
        \PY{n}{data\PYZus{}dir} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{inception/5h/}\PY{l+s+s2}{\PYZdq{}}
        
        \PY{c+c1}{\PYZsh{} File containing the TensorFlow graph definition. (Downloaded)}
        \PY{n}{path\PYZus{}graph\PYZus{}def} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{tensorflow\PYZus{}inception\PYZus{}graph.pb}\PY{l+s+s2}{\PYZdq{}}
        
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        
        
        \PY{k}{def} \PY{n+nf}{maybe\PYZus{}download}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Download the Inception model from the internet if it does not already}
        \PY{l+s+sd}{    exist in the data\PYZus{}dir. The file is about 50 MB.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Downloading Inception 5h Model ...}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{maybe\PYZus{}download\PYZus{}and\PYZus{}extract}\PY{p}{(}\PY{n}{url}\PY{o}{=}\PY{n}{data\PYZus{}url}\PY{p}{,} \PY{n}{download\PYZus{}dir}\PY{o}{=}\PY{n}{data\PYZus{}dir}\PY{p}{)}
        
        
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        
        
        \PY{k}{class} \PY{n+nc}{Inception5h}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    The Inception model is a Deep Neural Network which has already been}
        \PY{l+s+sd}{    trained for classifying images into 1000 different categories.}
        
        \PY{l+s+sd}{    When you create a new instance of this class, the Inception model}
        \PY{l+s+sd}{    will be loaded and can be used immediately without training.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Name of the tensor for feeding the input image.}
            \PY{n}{tensor\PYZus{}name\PYZus{}input\PYZus{}image} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{input:0}\PY{l+s+s2}{\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Names for some of the commonly used layers in the Inception model.}
            \PY{n}{layer\PYZus{}names} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{conv2d0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{conv2d1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{conv2d2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                           \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mixed3a}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mixed3b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                           \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mixed4a}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mixed4b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mixed4c}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mixed4d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mixed4e}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                           \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mixed5a}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mixed5b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        
            \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Now load the Inception model from file. The way TensorFlow}
                \PY{c+c1}{\PYZsh{} does this is confusing and requires several steps.}
        
                \PY{c+c1}{\PYZsh{} Create a new TensorFlow computational graph.}
                \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{graph} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Graph}\PY{p}{(}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Set the new graph as the default.}
                \PY{k}{with} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{graph}\PY{o}{.}\PY{n}{as\PYZus{}default}\PY{p}{(}\PY{p}{)}\PY{p}{:}
        
                    \PY{c+c1}{\PYZsh{} TensorFlow graphs are saved to disk as so\PYZhy{}called Protocol Buffers}
                    \PY{c+c1}{\PYZsh{} aka. proto\PYZhy{}bufs which is a file\PYZhy{}format that works on multiple}
                    \PY{c+c1}{\PYZsh{} platforms. In this case it is saved as a binary file.}
        
                    \PY{c+c1}{\PYZsh{} Open the graph\PYZhy{}def file for binary reading.}
                    \PY{n}{path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{data\PYZus{}dir}\PY{p}{,} \PY{n}{path\PYZus{}graph\PYZus{}def}\PY{p}{)}
                    \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{gfile}\PY{o}{.}\PY{n}{FastGFile}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{file}\PY{p}{:}
                        \PY{c+c1}{\PYZsh{} The graph\PYZhy{}def is a saved copy of a TensorFlow graph.}
                        \PY{c+c1}{\PYZsh{} First we need to create an empty graph\PYZhy{}def.}
                        \PY{n}{graph\PYZus{}def} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{GraphDef}\PY{p}{(}\PY{p}{)}
        
                        \PY{c+c1}{\PYZsh{} Then we load the proto\PYZhy{}buf file into the graph\PYZhy{}def.}
                        \PY{n}{graph\PYZus{}def}\PY{o}{.}\PY{n}{ParseFromString}\PY{p}{(}\PY{n}{file}\PY{o}{.}\PY{n}{read}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        
                        \PY{c+c1}{\PYZsh{} Finally we import the graph\PYZhy{}def to the default TensorFlow graph.}
                        \PY{n}{tf}\PY{o}{.}\PY{n}{import\PYZus{}graph\PYZus{}def}\PY{p}{(}\PY{n}{graph\PYZus{}def}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
                        \PY{c+c1}{\PYZsh{} Now self.graph holds the Inception model from the proto\PYZhy{}buf file.}
        
                    \PY{c+c1}{\PYZsh{} Get a reference to the tensor for inputting images to the graph.}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{input} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{tensor\PYZus{}name\PYZus{}input\PYZus{}image}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} Get references to the tensors for the commonly used layers.}
                    \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{layer\PYZus{}tensors} \PY{o}{=} \PY{p}{[}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{graph}\PY{o}{.}\PY{n}{get\PYZus{}tensor\PYZus{}by\PYZus{}name}\PY{p}{(}\PY{n}{name} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{:0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{k}{for} \PY{n}{name} \PY{o+ow}{in} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{layer\PYZus{}names}\PY{p}{]}
        
            \PY{k}{def} \PY{n+nf}{create\PYZus{}feed\PYZus{}dict}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
                \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{        Create and return a feed\PYZhy{}dict with an image.}
        
        \PY{l+s+sd}{        :param image:}
        \PY{l+s+sd}{            The input image is a 3\PYZhy{}dim array which is already decoded.}
        \PY{l+s+sd}{            The pixels MUST be values between 0 and 255 (float or int).}
        
        \PY{l+s+sd}{        :return:}
        \PY{l+s+sd}{            Dict for feeding to the Inception graph in TensorFlow.}
        \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
        
                \PY{c+c1}{\PYZsh{} Expand 3\PYZhy{}dim array to 4\PYZhy{}dim by prepending an \PYZsq{}empty\PYZsq{} dimension.}
                \PY{c+c1}{\PYZsh{} This is because we are only feeding a single image, but the}
                \PY{c+c1}{\PYZsh{} Inception model was built to take multiple images as input.}
                \PY{n}{image} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{expand\PYZus{}dims}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Image is passed in as a 3\PYZhy{}dim array of raw pixel\PYZhy{}values.}
                \PY{n}{feed\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{tensor\PYZus{}name\PYZus{}input\PYZus{}image}\PY{p}{:} \PY{n}{image}\PY{p}{\PYZcb{}}
        
                \PY{k}{return} \PY{n}{feed\PYZus{}dict}
        
            \PY{k}{def} \PY{n+nf}{get\PYZus{}gradient}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{tensor}\PY{p}{)}\PY{p}{:}
                \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{        Get the gradient of the given tensor with respect to}
        \PY{l+s+sd}{        the input image. This allows us to modify the input}
        \PY{l+s+sd}{        image so as to maximize the given tensor.}
        
        \PY{l+s+sd}{        For use in e.g. DeepDream and Visual Analysis.}
        
        \PY{l+s+sd}{        :param tensor:}
        \PY{l+s+sd}{            The tensor whose value we want to maximize}
        \PY{l+s+sd}{            by changing the input image.}
        
        \PY{l+s+sd}{        :return:}
        \PY{l+s+sd}{            Gradient for the tensor with regard to the input image.}
        \PY{l+s+sd}{        \PYZdq{}\PYZdq{}\PYZdq{}}
        
                \PY{c+c1}{\PYZsh{} Set the graph as default so we can add operations to it.}
                \PY{k}{with} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{graph}\PY{o}{.}\PY{n}{as\PYZus{}default}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} Square the tensor\PYZhy{}values.}
                    \PY{c+c1}{\PYZsh{} You can try and remove this to see the effect.}
                    \PY{n}{tensor} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{square}\PY{p}{(}\PY{n}{tensor}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} Average the tensor so we get a single scalar value.}
                    \PY{n}{tensor\PYZus{}mean} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{tensor}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} Use TensorFlow to automatically create a mathematical}
                    \PY{c+c1}{\PYZsh{} formula for the gradient using the chain\PYZhy{}rule of}
                    \PY{c+c1}{\PYZsh{} differentiation.}
                    \PY{n}{gradient} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{gradients}\PY{p}{(}\PY{n}{tensor\PYZus{}mean}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{input}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
        
                \PY{k}{return} \PY{n}{gradient}
\end{Verbatim}

    \hypertarget{flowchart}{%
\subsection{Flowchart}\label{flowchart}}

This flowchart shows roughly the idea of the DeepDream algorithm. We use
the Inception model which has many more layers than shown here. We use
TensorFlow to automatically derive the gradient for a given layer in the
network with respect to the input image. The gradient is then used to
update the input image. This procedure is repeated a number of times
until patterns have emerged and we are satisfied with the resulting
image.

What happens is that the neural network sees small traces of the
patterns in the image and we merely amplify the patterns using the
gradient.

There are some details of the DeepDream algorithm not shown here,
e.g.~that the gradient is blurred, which has some advantages discussed
further below. The gradient is also calculated in tiles so it can work
on very high-resolution images without running out of computer memory.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{Image}\PY{p}{,} \PY{n}{display}
        \PY{n}{Image}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{deepdream\PYZus{}flowchart.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\texttt{\color{outcolor}Out[{\color{outcolor}1}]:}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_7_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    \hypertarget{recursive-optimization}{%
\subsubsection{Recursive Optimization}\label{recursive-optimization}}

The Inception model was trained on images of fairly low resolution,
presumably 200-300 pixels. So when we use images with much larger
resolution, the DeepDream algorithm will create many small patterns in
the image.

One solution is to downscale the input image to 200-300 pixels. But such
a low resolution is pixelated and ugly.

Another solution is to repeatedly downscale the original image and run
the DeepDream algorithm on each of the smaller versions of the image.
This creates larger patterns in the image that are then refined at the
higher resolution.

This flowchart shows roughly the idea. The algorithm is implemented
recursively and supports any number of downscaling levels. The algorithm
has several details not shown here, e.g.~that the images are blurred
slightly before being downscaled, and the original image is only blended
somewhat with the DeepDream images to add some of the original detail
back in.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{Image}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{deepdream\PYZus{}recursive\PYZus{}flowchart.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}
\texttt{\color{outcolor}Out[{\color{outcolor}2}]:}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_9_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    

    \hypertarget{imports}{%
\subsection{Imports}\label{imports}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k}{as} \PY{n+nn}{tf}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{random}
        \PY{k+kn}{import} \PY{n+nn}{math}
        
        \PY{c+c1}{\PYZsh{} Image manipulation.}
        \PY{k+kn}{import} \PY{n+nn}{PIL}\PY{n+nn}{.}\PY{n+nn}{Image}
        \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{ndimage}\PY{n+nn}{.}\PY{n+nn}{filters} \PY{k}{import} \PY{n}{gaussian\PYZus{}filter}
\end{Verbatim}

    This was developed using Python 3.5.2 (Anaconda) and TensorFlow version:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{tf}\PY{o}{.}\PY{n}{\PYZus{}\PYZus{}version\PYZus{}\PYZus{}}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}12}]:} '1.13.1'
\end{Verbatim}
            
    \hypertarget{inception-model}{%
\subsection{Inception Model}\label{inception-model}}

    In this tutorial we will use another variant of the Inception model. It
is unclear exactly which variant it is, because the Google developers
have (as usual) neglected to document their work. We will therefore
refer to it as the ``Inception 5h'' model because that is the name of
the zip-file, although it actually appears to be a simpler and earlier
version of the Inception model.

The Inception 5h model is used because it is easier to work with: It
takes input images of any size, and it seems to create prettier pictures
than the Inception v3 model.

    The Inception 5h model is downloaded from the internet. This is the
default directory where you want to save the data-files. The directory
will be created if it does not exist.

    Download the data for the Inception model if it doesn't already exist in
the directory. It is 50 MB.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{n}{maybe\PYZus{}download}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Downloading Inception 5h Model {\ldots}
- Download progress: 100.0\%
Download finished. Extracting files.
Done.

    \end{Verbatim}

    Load the Inception model so it is ready to be used.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{n}{model} \PY{o}{=} \PY{n}{Inception5h}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
WARNING:tensorflow:From <ipython-input-2-40a0bd549668>:68: FastGFile.\_\_init\_\_ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.

    \end{Verbatim}

    The Inception 5h model has many layers that can be used for
DeepDreaming. We have made a list of the 12 most commonly used layers
for easy reference.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n+nb}{len}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{layer\PYZus{}tensors}\PY{p}{)}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}15}]:} 12
\end{Verbatim}
            
    \hypertarget{helper-functions-for-image-manipulation}{%
\subsection{Helper-functions for image
manipulation}\label{helper-functions-for-image-manipulation}}

    This function loads an image and returns it as a numpy array of
floating-points.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{load\PYZus{}image}\PY{p}{(}\PY{n}{filename}\PY{p}{)}\PY{p}{:}
            \PY{n}{image} \PY{o}{=} \PY{n}{PIL}\PY{o}{.}\PY{n}{Image}\PY{o}{.}\PY{n}{open}\PY{p}{(}\PY{n}{filename}\PY{p}{)}
        
            \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{float32}\PY{p}{(}\PY{n}{image}\PY{p}{)}
\end{Verbatim}

    Save an image as a jpeg-file. The image is given as a numpy array with
pixel-values between 0 and 255.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{save\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{filename}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} Ensure the pixel\PYZhy{}values are between 0 and 255.}
            \PY{n}{image} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{clip}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{255.0}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Convert to bytes.}
            \PY{n}{image} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Write the image\PYZhy{}file in jpeg\PYZhy{}format.}
            \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{filename}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wb}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{file}\PY{p}{:}
                \PY{n}{PIL}\PY{o}{.}\PY{n}{Image}\PY{o}{.}\PY{n}{fromarray}\PY{p}{(}\PY{n}{image}\PY{p}{)}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{n}{file}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{jpeg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}

    This function plots an image. Using matplotlib gives low-resolution
images. Using PIL gives pretty pictures.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} Assume the pixel\PYZhy{}values are scaled between 0 and 255.}
            
            \PY{k}{if} \PY{k+kc}{False}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Convert the pixel\PYZhy{}values to the range between 0.0 and 1.0}
                \PY{n}{image} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{clip}\PY{p}{(}\PY{n}{image}\PY{o}{/}\PY{l+m+mf}{255.0}\PY{p}{,} \PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{)}
                
                \PY{c+c1}{\PYZsh{} Plot using matplotlib.}
                \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{interpolation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lanczos}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Ensure the pixel\PYZhy{}values are between 0 and 255.}
                \PY{n}{image} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{clip}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{255.0}\PY{p}{)}
                
                \PY{c+c1}{\PYZsh{} Convert pixels to bytes.}
                \PY{n}{image} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Convert to a PIL\PYZhy{}image and display it.}
                \PY{n}{display}\PY{p}{(}\PY{n}{PIL}\PY{o}{.}\PY{n}{Image}\PY{o}{.}\PY{n}{fromarray}\PY{p}{(}\PY{n}{image}\PY{p}{)}\PY{p}{)}
\end{Verbatim}

    Normalize an image so its values are between 0.0 and 1.0. This is useful
for plotting the gradient.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{normalize\PYZus{}image}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} Get the min and max values for all pixels in the input.}
            \PY{n}{x\PYZus{}min} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{p}{)}
            \PY{n}{x\PYZus{}max} \PY{o}{=} \PY{n}{x}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Normalize so all values are between 0.0 and 1.0}
            \PY{n}{x\PYZus{}norm} \PY{o}{=} \PY{p}{(}\PY{n}{x} \PY{o}{\PYZhy{}} \PY{n}{x\PYZus{}min}\PY{p}{)} \PY{o}{/} \PY{p}{(}\PY{n}{x\PYZus{}max} \PY{o}{\PYZhy{}} \PY{n}{x\PYZus{}min}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{x\PYZus{}norm}
\end{Verbatim}

    This function plots the gradient after normalizing it.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}gradient}\PY{p}{(}\PY{n}{gradient}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} Normalize the gradient so it is between 0.0 and 1.0}
            \PY{n}{gradient\PYZus{}normalized} \PY{o}{=} \PY{n}{normalize\PYZus{}image}\PY{p}{(}\PY{n}{gradient}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Plot the normalized gradient.}
            \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{gradient\PYZus{}normalized}\PY{p}{,} \PY{n}{interpolation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bilinear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    This function resizes an image. It can take a size-argument where you
give it the exact pixel-size you want the image to be e.g. (100, 200).
Or it can take a factor-argument where you give it the rescaling-factor
you want to use e.g.~0.5 for halving the size of the image in each
dimension.

This is implemented using PIL which is a bit lengthy because we are
working on numpy arrays where the pixels are floating-point values. This
is not supported by PIL so the image must be converted to 8-bit bytes
while ensuring the pixel-values are within the proper limits. Then the
image is resized and converted back to floating-point values.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{resize\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{factor}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} If a rescaling\PYZhy{}factor is provided then use it.}
            \PY{k}{if} \PY{n}{factor} \PY{o+ow}{is} \PY{o+ow}{not} \PY{k+kc}{None}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Scale the numpy array\PYZsq{}s shape for height and width.}
                \PY{n}{size} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{image}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)} \PY{o}{*} \PY{n}{factor}
                
                \PY{c+c1}{\PYZsh{} The size is floating\PYZhy{}point because it was scaled.}
                \PY{c+c1}{\PYZsh{} PIL requires the size to be integers.}
                \PY{n}{size} \PY{o}{=} \PY{n}{size}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}
            \PY{k}{else}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Ensure the size has length 2.}
                \PY{n}{size} \PY{o}{=} \PY{n}{size}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{2}\PY{p}{]}
            
            \PY{c+c1}{\PYZsh{} The height and width is reversed in numpy vs. PIL.}
            \PY{n}{size} \PY{o}{=} \PY{n+nb}{tuple}\PY{p}{(}\PY{n+nb}{reversed}\PY{p}{(}\PY{n}{size}\PY{p}{)}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Ensure the pixel\PYZhy{}values are between 0 and 255.}
            \PY{n}{img} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{clip}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{255.0}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Convert the pixels to 8\PYZhy{}bit bytes.}
            \PY{n}{img} \PY{o}{=} \PY{n}{img}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{uint8}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Create PIL\PYZhy{}object from numpy array.}
            \PY{n}{img} \PY{o}{=} \PY{n}{PIL}\PY{o}{.}\PY{n}{Image}\PY{o}{.}\PY{n}{fromarray}\PY{p}{(}\PY{n}{img}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Resize the image.}
            \PY{n}{img\PYZus{}resized} \PY{o}{=} \PY{n}{img}\PY{o}{.}\PY{n}{resize}\PY{p}{(}\PY{n}{size}\PY{p}{,} \PY{n}{PIL}\PY{o}{.}\PY{n}{Image}\PY{o}{.}\PY{n}{LANCZOS}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Convert 8\PYZhy{}bit pixel values back to floating\PYZhy{}point.}
            \PY{n}{img\PYZus{}resized} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{float32}\PY{p}{(}\PY{n}{img\PYZus{}resized}\PY{p}{)}
        
            \PY{k}{return} \PY{n}{img\PYZus{}resized}
\end{Verbatim}

    \hypertarget{deepdream-algorithm}{%
\subsection{DeepDream Algorithm}\label{deepdream-algorithm}}

    \hypertarget{gradient}{%
\subsubsection{Gradient}\label{gradient}}

    The following helper-functions calculate the gradient of an input image
for use in the DeepDream algorithm. The Inception 5h model can accept
images of any size, but very large images may use many giga-bytes of
RAM. In order to keep the RAM-usage low we will split the input image
into smaller tiles and calculate the gradient for each of the tiles.

However, this may result in visible lines in the final images produced
by the DeepDream algorithm. We therefore choose the tiles randomly so
the locations of the tiles are always different. This makes the seams
between the tiles invisible in the final DeepDream image.

    This is a helper-function for determining an appropriate tile-size. The
desired tile-size is e.g.~400x400 pixels, but the actual tile-size will
depend on the image-dimensions.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{get\PYZus{}tile\PYZus{}size}\PY{p}{(}\PY{n}{num\PYZus{}pixels}\PY{p}{,} \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{400}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    num\PYZus{}pixels is the number of pixels in a dimension of the image.}
        \PY{l+s+sd}{    tile\PYZus{}size is the desired tile\PYZhy{}size.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} How many times can we repeat a tile of the desired size.}
            \PY{n}{num\PYZus{}tiles} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{round}\PY{p}{(}\PY{n}{num\PYZus{}pixels} \PY{o}{/} \PY{n}{tile\PYZus{}size}\PY{p}{)}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Ensure that there is at least 1 tile.}
            \PY{n}{num\PYZus{}tiles} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{num\PYZus{}tiles}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} The actual tile\PYZhy{}size.}
            \PY{n}{actual\PYZus{}tile\PYZus{}size} \PY{o}{=} \PY{n}{math}\PY{o}{.}\PY{n}{ceil}\PY{p}{(}\PY{n}{num\PYZus{}pixels} \PY{o}{/} \PY{n}{num\PYZus{}tiles}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{actual\PYZus{}tile\PYZus{}size}
\end{Verbatim}

    This helper-function computes the gradient for an input image. The image
is split into tiles and the gradient is calculated for each tile. The
tiles are chosen randomly to avoid visible seams / lines in the final
DeepDream image.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{tiled\PYZus{}gradient}\PY{p}{(}\PY{n}{gradient}\PY{p}{,} \PY{n}{image}\PY{p}{,} \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{400}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} Allocate an array for the gradient of the entire image.}
            \PY{n}{grad} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros\PYZus{}like}\PY{p}{(}\PY{n}{image}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Number of pixels for the x\PYZhy{} and y\PYZhy{}axes.}
            \PY{n}{x\PYZus{}max}\PY{p}{,} \PY{n}{y\PYZus{}max}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{shape}
        
            \PY{c+c1}{\PYZsh{} Tile\PYZhy{}size for the x\PYZhy{}axis.}
            \PY{n}{x\PYZus{}tile\PYZus{}size} \PY{o}{=} \PY{n}{get\PYZus{}tile\PYZus{}size}\PY{p}{(}\PY{n}{num\PYZus{}pixels}\PY{o}{=}\PY{n}{x\PYZus{}max}\PY{p}{,} \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{n}{tile\PYZus{}size}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} 1/4 of the tile\PYZhy{}size.}
            \PY{n}{x\PYZus{}tile\PYZus{}size4} \PY{o}{=} \PY{n}{x\PYZus{}tile\PYZus{}size} \PY{o}{/}\PY{o}{/} \PY{l+m+mi}{4}
        
            \PY{c+c1}{\PYZsh{} Tile\PYZhy{}size for the y\PYZhy{}axis.}
            \PY{n}{y\PYZus{}tile\PYZus{}size} \PY{o}{=} \PY{n}{get\PYZus{}tile\PYZus{}size}\PY{p}{(}\PY{n}{num\PYZus{}pixels}\PY{o}{=}\PY{n}{y\PYZus{}max}\PY{p}{,} \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{n}{tile\PYZus{}size}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} 1/4 of the tile\PYZhy{}size}
            \PY{n}{y\PYZus{}tile\PYZus{}size4} \PY{o}{=} \PY{n}{y\PYZus{}tile\PYZus{}size} \PY{o}{/}\PY{o}{/} \PY{l+m+mi}{4}
        
            \PY{c+c1}{\PYZsh{} Random start\PYZhy{}position for the tiles on the x\PYZhy{}axis.}
            \PY{c+c1}{\PYZsh{} The random value is between \PYZhy{}3/4 and \PYZhy{}1/4 of the tile\PYZhy{}size.}
            \PY{c+c1}{\PYZsh{} This is so the border\PYZhy{}tiles are at least 1/4 of the tile\PYZhy{}size,}
            \PY{c+c1}{\PYZsh{} otherwise the tiles may be too small which creates noisy gradients.}
            \PY{n}{x\PYZus{}start} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{3}\PY{o}{*}\PY{n}{x\PYZus{}tile\PYZus{}size4}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{n}{x\PYZus{}tile\PYZus{}size4}\PY{p}{)}
        
            \PY{k}{while} \PY{n}{x\PYZus{}start} \PY{o}{\PYZlt{}} \PY{n}{x\PYZus{}max}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} End\PYZhy{}position for the current tile.}
                \PY{n}{x\PYZus{}end} \PY{o}{=} \PY{n}{x\PYZus{}start} \PY{o}{+} \PY{n}{x\PYZus{}tile\PYZus{}size}
                
                \PY{c+c1}{\PYZsh{} Ensure the tile\PYZsq{}s start\PYZhy{} and end\PYZhy{}positions are valid.}
                \PY{n}{x\PYZus{}start\PYZus{}lim} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n}{x\PYZus{}start}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}
                \PY{n}{x\PYZus{}end\PYZus{}lim} \PY{o}{=} \PY{n+nb}{min}\PY{p}{(}\PY{n}{x\PYZus{}end}\PY{p}{,} \PY{n}{x\PYZus{}max}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Random start\PYZhy{}position for the tiles on the y\PYZhy{}axis.}
                \PY{c+c1}{\PYZsh{} The random value is between \PYZhy{}3/4 and \PYZhy{}1/4 of the tile\PYZhy{}size.}
                \PY{n}{y\PYZus{}start} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{3}\PY{o}{*}\PY{n}{y\PYZus{}tile\PYZus{}size4}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{n}{y\PYZus{}tile\PYZus{}size4}\PY{p}{)}
        
                \PY{k}{while} \PY{n}{y\PYZus{}start} \PY{o}{\PYZlt{}} \PY{n}{y\PYZus{}max}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} End\PYZhy{}position for the current tile.}
                    \PY{n}{y\PYZus{}end} \PY{o}{=} \PY{n}{y\PYZus{}start} \PY{o}{+} \PY{n}{y\PYZus{}tile\PYZus{}size}
        
                    \PY{c+c1}{\PYZsh{} Ensure the tile\PYZsq{}s start\PYZhy{} and end\PYZhy{}positions are valid.}
                    \PY{n}{y\PYZus{}start\PYZus{}lim} \PY{o}{=} \PY{n+nb}{max}\PY{p}{(}\PY{n}{y\PYZus{}start}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}
                    \PY{n}{y\PYZus{}end\PYZus{}lim} \PY{o}{=} \PY{n+nb}{min}\PY{p}{(}\PY{n}{y\PYZus{}end}\PY{p}{,} \PY{n}{y\PYZus{}max}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} Get the image\PYZhy{}tile.}
                    \PY{n}{img\PYZus{}tile} \PY{o}{=} \PY{n}{image}\PY{p}{[}\PY{n}{x\PYZus{}start\PYZus{}lim}\PY{p}{:}\PY{n}{x\PYZus{}end\PYZus{}lim}\PY{p}{,}
                                     \PY{n}{y\PYZus{}start\PYZus{}lim}\PY{p}{:}\PY{n}{y\PYZus{}end\PYZus{}lim}\PY{p}{,} \PY{p}{:}\PY{p}{]}
        
                    \PY{c+c1}{\PYZsh{} Create a feed\PYZhy{}dict with the image\PYZhy{}tile.}
                    \PY{n}{feed\PYZus{}dict} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{create\PYZus{}feed\PYZus{}dict}\PY{p}{(}\PY{n}{image}\PY{o}{=}\PY{n}{img\PYZus{}tile}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} Use TensorFlow to calculate the gradient\PYZhy{}value.}
                    \PY{n}{g} \PY{o}{=} \PY{n}{session}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{gradient}\PY{p}{,} \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{n}{feed\PYZus{}dict}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} Normalize the gradient for the tile. This is}
                    \PY{c+c1}{\PYZsh{} necessary because the tiles may have very different}
                    \PY{c+c1}{\PYZsh{} values. Normalizing gives a more coherent gradient.}
                    \PY{n}{g} \PY{o}{/}\PY{o}{=} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{g}\PY{p}{)} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}8}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} Store the tile\PYZsq{}s gradient at the appropriate location.}
                    \PY{n}{grad}\PY{p}{[}\PY{n}{x\PYZus{}start\PYZus{}lim}\PY{p}{:}\PY{n}{x\PYZus{}end\PYZus{}lim}\PY{p}{,}
                         \PY{n}{y\PYZus{}start\PYZus{}lim}\PY{p}{:}\PY{n}{y\PYZus{}end\PYZus{}lim}\PY{p}{,} \PY{p}{:}\PY{p}{]} \PY{o}{=} \PY{n}{g}
                    
                    \PY{c+c1}{\PYZsh{} Advance the start\PYZhy{}position for the y\PYZhy{}axis.}
                    \PY{n}{y\PYZus{}start} \PY{o}{=} \PY{n}{y\PYZus{}end}
        
                \PY{c+c1}{\PYZsh{} Advance the start\PYZhy{}position for the x\PYZhy{}axis.}
                \PY{n}{x\PYZus{}start} \PY{o}{=} \PY{n}{x\PYZus{}end}
        
            \PY{k}{return} \PY{n}{grad}
\end{Verbatim}

    \hypertarget{optimize-image}{%
\subsubsection{Optimize Image}\label{optimize-image}}

This function is the main optimization-loop for the DeepDream algorithm.
It calculates the gradient of the given layer of the Inception model
with regard to the input image. The gradient is then added to the input
image so the mean value of the layer-tensor is increased. This process
is repeated a number of times and amplifies whatever patterns the
Inception model sees in the input image.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{optimize\PYZus{}image}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{p}{,} \PY{n}{image}\PY{p}{,}
                           \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{3.0}\PY{p}{,} \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{400}\PY{p}{,}
                           \PY{n}{show\PYZus{}gradient}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Use gradient ascent to optimize an image so it maximizes the}
        \PY{l+s+sd}{    mean value of the given layer\PYZus{}tensor.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Parameters:}
        \PY{l+s+sd}{    layer\PYZus{}tensor: Reference to a tensor that will be maximized.}
        \PY{l+s+sd}{    image: Input image used as the starting point.}
        \PY{l+s+sd}{    num\PYZus{}iterations: Number of optimization iterations to perform.}
        \PY{l+s+sd}{    step\PYZus{}size: Scale for each step of the gradient ascent.}
        \PY{l+s+sd}{    tile\PYZus{}size: Size of the tiles when calculating the gradient.}
        \PY{l+s+sd}{    show\PYZus{}gradient: Plot the gradient in each iteration.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Copy the image so we don\PYZsq{}t overwrite the original image.}
            \PY{n}{img} \PY{o}{=} \PY{n}{image}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
            
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Image before:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{plot\PYZus{}image}\PY{p}{(}\PY{n}{img}\PY{p}{)}
        
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Processing image: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{end}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Use TensorFlow to get the mathematical function for the}
            \PY{c+c1}{\PYZsh{} gradient of the given layer\PYZhy{}tensor with regard to the}
            \PY{c+c1}{\PYZsh{} input image. This may cause TensorFlow to add the same}
            \PY{c+c1}{\PYZsh{} math\PYZhy{}expressions to the graph each time this function is called.}
            \PY{c+c1}{\PYZsh{} It may use a lot of RAM and could be moved outside the function.}
            \PY{n}{gradient} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{get\PYZus{}gradient}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{p}{)}
            
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{num\PYZus{}iterations}\PY{p}{)}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Calculate the value of the gradient.}
                \PY{c+c1}{\PYZsh{} This tells us how to change the image so as to}
                \PY{c+c1}{\PYZsh{} maximize the mean of the given layer\PYZhy{}tensor.}
                \PY{n}{grad} \PY{o}{=} \PY{n}{tiled\PYZus{}gradient}\PY{p}{(}\PY{n}{gradient}\PY{o}{=}\PY{n}{gradient}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{n}{img}\PY{p}{,}
                                      \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{n}{tile\PYZus{}size}\PY{p}{)}
                
                \PY{c+c1}{\PYZsh{} Blur the gradient with different amounts and add}
                \PY{c+c1}{\PYZsh{} them together. The blur amount is also increased}
                \PY{c+c1}{\PYZsh{} during the optimization. This was found to give}
                \PY{c+c1}{\PYZsh{} nice, smooth images. You can try and change the formulas.}
                \PY{c+c1}{\PYZsh{} The blur\PYZhy{}amount is called sigma (0=no blur, 1=low blur, etc.)}
                \PY{c+c1}{\PYZsh{} We could call gaussian\PYZus{}filter(grad, sigma=(sigma, sigma, 0.0))}
                \PY{c+c1}{\PYZsh{} which would not blur the colour\PYZhy{}channel. This tends to}
                \PY{c+c1}{\PYZsh{} give psychadelic / pastel colours in the resulting images.}
                \PY{c+c1}{\PYZsh{} When the colour\PYZhy{}channel is also blurred the colours of the}
                \PY{c+c1}{\PYZsh{} input image are mostly retained in the output image.}
                \PY{n}{sigma} \PY{o}{=} \PY{p}{(}\PY{n}{i} \PY{o}{*} \PY{l+m+mf}{4.0}\PY{p}{)} \PY{o}{/} \PY{n}{num\PYZus{}iterations} \PY{o}{+} \PY{l+m+mf}{0.5}
                \PY{n}{grad\PYZus{}smooth1} \PY{o}{=} \PY{n}{gaussian\PYZus{}filter}\PY{p}{(}\PY{n}{grad}\PY{p}{,} \PY{n}{sigma}\PY{o}{=}\PY{n}{sigma}\PY{p}{)}
                \PY{n}{grad\PYZus{}smooth2} \PY{o}{=} \PY{n}{gaussian\PYZus{}filter}\PY{p}{(}\PY{n}{grad}\PY{p}{,} \PY{n}{sigma}\PY{o}{=}\PY{n}{sigma}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)}
                \PY{n}{grad\PYZus{}smooth3} \PY{o}{=} \PY{n}{gaussian\PYZus{}filter}\PY{p}{(}\PY{n}{grad}\PY{p}{,} \PY{n}{sigma}\PY{o}{=}\PY{n}{sigma}\PY{o}{*}\PY{l+m+mf}{0.5}\PY{p}{)}
                \PY{n}{grad} \PY{o}{=} \PY{p}{(}\PY{n}{grad\PYZus{}smooth1} \PY{o}{+} \PY{n}{grad\PYZus{}smooth2} \PY{o}{+} \PY{n}{grad\PYZus{}smooth3}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Scale the step\PYZhy{}size according to the gradient\PYZhy{}values.}
                \PY{c+c1}{\PYZsh{} This may not be necessary because the tiled\PYZhy{}gradient}
                \PY{c+c1}{\PYZsh{} is already normalized.}
                \PY{n}{step\PYZus{}size\PYZus{}scaled} \PY{o}{=} \PY{n}{step\PYZus{}size} \PY{o}{/} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{grad}\PY{p}{)} \PY{o}{+} \PY{l+m+mf}{1e\PYZhy{}8}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Update the image by following the gradient.}
                \PY{n}{img} \PY{o}{+}\PY{o}{=} \PY{n}{grad} \PY{o}{*} \PY{n}{step\PYZus{}size\PYZus{}scaled}
        
                \PY{k}{if} \PY{n}{show\PYZus{}gradient}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} Print statistics for the gradient.}
                    \PY{n}{msg} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Gradient min: }\PY{l+s+si}{\PYZob{}0:\PYZgt{}9.6f\PYZcb{}}\PY{l+s+s2}{, max: }\PY{l+s+si}{\PYZob{}1:\PYZgt{}9.6f\PYZcb{}}\PY{l+s+s2}{, stepsize: }\PY{l+s+si}{\PYZob{}2:\PYZgt{}9.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}
                    \PY{n+nb}{print}\PY{p}{(}\PY{n}{msg}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{grad}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{grad}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{step\PYZus{}size\PYZus{}scaled}\PY{p}{)}\PY{p}{)}
        
                    \PY{c+c1}{\PYZsh{} Plot the gradient.}
                    \PY{n}{plot\PYZus{}gradient}\PY{p}{(}\PY{n}{grad}\PY{p}{)}
                \PY{k}{else}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{} Otherwise show a little progress\PYZhy{}indicator.}
                    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{. }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{end}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        
            \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Image after:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{n}{plot\PYZus{}image}\PY{p}{(}\PY{n}{img}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{img}
\end{Verbatim}

    \hypertarget{recursive-image-optimization}{%
\subsubsection{Recursive Image
Optimization}\label{recursive-image-optimization}}

The Inception model was trained on fairly small images. The exact size
is unclear but maybe 200-300 pixels in each dimension. If we use larger
images such as 1920x1080 pixels then the \texttt{optimize\_image()}
function above will add many small patterns to the image.

This helper-function downscales the input image several times and runs
each downscaled version through the \texttt{optimize\_image()} function
above. This results in larger patterns in the final image. It also
speeds up the computation.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{recursive\PYZus{}optimize}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{p}{,} \PY{n}{image}\PY{p}{,}
                               \PY{n}{num\PYZus{}repeats}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{rescale\PYZus{}factor}\PY{o}{=}\PY{l+m+mf}{0.7}\PY{p}{,} \PY{n}{blend}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}
                               \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{3.0}\PY{p}{,}
                               \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{400}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
        \PY{l+s+sd}{    Recursively blur and downscale the input image.}
        \PY{l+s+sd}{    Each downscaled image is run through the optimize\PYZus{}image()}
        \PY{l+s+sd}{    function to amplify the patterns that the Inception model sees.}
        
        \PY{l+s+sd}{    Parameters:}
        \PY{l+s+sd}{    image: Input image used as the starting point.}
        \PY{l+s+sd}{    rescale\PYZus{}factor: Downscaling factor for the image.}
        \PY{l+s+sd}{    num\PYZus{}repeats: Number of times to downscale the image.}
        \PY{l+s+sd}{    blend: Factor for blending the original and processed images.}
        
        \PY{l+s+sd}{    Parameters passed to optimize\PYZus{}image():}
        \PY{l+s+sd}{    layer\PYZus{}tensor: Reference to a tensor that will be maximized.}
        \PY{l+s+sd}{    num\PYZus{}iterations: Number of optimization iterations to perform.}
        \PY{l+s+sd}{    step\PYZus{}size: Scale for each step of the gradient ascent.}
        \PY{l+s+sd}{    tile\PYZus{}size: Size of the tiles when calculating the gradient.}
        \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Do a recursive step?}
            \PY{k}{if} \PY{n}{num\PYZus{}repeats}\PY{o}{\PYZgt{}}\PY{l+m+mi}{0}\PY{p}{:}
                \PY{c+c1}{\PYZsh{} Blur the input image to prevent artifacts when downscaling.}
                \PY{c+c1}{\PYZsh{} The blur amount is controlled by sigma. Note that the}
                \PY{c+c1}{\PYZsh{} colour\PYZhy{}channel is not blurred as it would make the image gray.}
                \PY{n}{sigma} \PY{o}{=} \PY{l+m+mf}{0.5}
                \PY{n}{img\PYZus{}blur} \PY{o}{=} \PY{n}{gaussian\PYZus{}filter}\PY{p}{(}\PY{n}{image}\PY{p}{,} \PY{n}{sigma}\PY{o}{=}\PY{p}{(}\PY{n}{sigma}\PY{p}{,} \PY{n}{sigma}\PY{p}{,} \PY{l+m+mf}{0.0}\PY{p}{)}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Downscale the image.}
                \PY{n}{img\PYZus{}downscaled} \PY{o}{=} \PY{n}{resize\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{o}{=}\PY{n}{img\PYZus{}blur}\PY{p}{,}
                                              \PY{n}{factor}\PY{o}{=}\PY{n}{rescale\PYZus{}factor}\PY{p}{)}
                    
                \PY{c+c1}{\PYZsh{} Recursive call to this function.}
                \PY{c+c1}{\PYZsh{} Subtract one from num\PYZus{}repeats and use the downscaled image.}
                \PY{n}{img\PYZus{}result} \PY{o}{=} \PY{n}{recursive\PYZus{}optimize}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{o}{=}\PY{n}{layer\PYZus{}tensor}\PY{p}{,}
                                                \PY{n}{image}\PY{o}{=}\PY{n}{img\PYZus{}downscaled}\PY{p}{,}
                                                \PY{n}{num\PYZus{}repeats}\PY{o}{=}\PY{n}{num\PYZus{}repeats}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,}
                                                \PY{n}{rescale\PYZus{}factor}\PY{o}{=}\PY{n}{rescale\PYZus{}factor}\PY{p}{,}
                                                \PY{n}{blend}\PY{o}{=}\PY{n}{blend}\PY{p}{,}
                                                \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{n}{num\PYZus{}iterations}\PY{p}{,}
                                                \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{n}{step\PYZus{}size}\PY{p}{,}
                                                \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{n}{tile\PYZus{}size}\PY{p}{)}
                
                \PY{c+c1}{\PYZsh{} Upscale the resulting image back to its original size.}
                \PY{n}{img\PYZus{}upscaled} \PY{o}{=} \PY{n}{resize\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{o}{=}\PY{n}{img\PYZus{}result}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{image}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
        
                \PY{c+c1}{\PYZsh{} Blend the original and processed images.}
                \PY{n}{image} \PY{o}{=} \PY{n}{blend} \PY{o}{*} \PY{n}{image} \PY{o}{+} \PY{p}{(}\PY{l+m+mf}{1.0} \PY{o}{\PYZhy{}} \PY{n}{blend}\PY{p}{)} \PY{o}{*} \PY{n}{img\PYZus{}upscaled}
        
            \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Recursive level:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{num\PYZus{}repeats}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Process the image using the DeepDream algorithm.}
            \PY{n}{img\PYZus{}result} \PY{o}{=} \PY{n}{optimize\PYZus{}image}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{o}{=}\PY{n}{layer\PYZus{}tensor}\PY{p}{,}
                                        \PY{n}{image}\PY{o}{=}\PY{n}{image}\PY{p}{,}
                                        \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{n}{num\PYZus{}iterations}\PY{p}{,}
                                        \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{n}{step\PYZus{}size}\PY{p}{,}
                                        \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{n}{tile\PYZus{}size}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{img\PYZus{}result}
\end{Verbatim}

    \hypertarget{tensorflow-session}{%
\subsection{TensorFlow Session}\label{tensorflow-session}}

    We need a TensorFlow session to execute the graph. This is an
interactive session so we can continue adding gradient functions to the
computational graph.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{n}{session} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{InteractiveSession}\PY{p}{(}\PY{n}{graph}\PY{o}{=}\PY{n}{model}\PY{o}{.}\PY{n}{graph}\PY{p}{)}
\end{Verbatim}

    \hypertarget{state-cup-dream}{%
\subsection{State Cup Dream}\label{state-cup-dream}}

    In the first example we have an image of my team winning the state
championship. Note how the colours of the original image are mostly kept
in the DeepDream images. This is because the gradient is blurred in its
colour-channels so it becomes somewhat gray-scale and mainly changes the
shape of the image and not so much its colour.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}41}]:} \PY{n}{image} \PY{o}{=} \PY{n}{load\PYZus{}image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{statecup.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plot\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_52_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    First we need a reference to the tensor inside the Inception model which
we will maximize in the DeepDream optimization algorithm. In this case
we select the entire 3rd layer of the Inception model (layer index 2).
It has 192 channels and we will try and maximize the average value
across all these channels.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}32}]:} \PY{n}{layer\PYZus{}tensor} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{layer\PYZus{}tensors}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}
         \PY{n}{layer\PYZus{}tensor}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}32}]:} <tf.Tensor 'conv2d2:0' shape=(?, ?, ?, 192) dtype=float32>
\end{Verbatim}
            
    Now run the DeepDream optimization algorithm for 10 iterations with a
step-size of 6.0, which is twice as high as in the recursive
optimizations below. We also show the gradient for each iteration and
you should note the visible artifacts in the seams between the tiles.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{n}{img\PYZus{}result} \PY{o}{=} \PY{n}{optimize\PYZus{}image}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{p}{,} \PY{n}{image}\PY{p}{,}
                            \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{6.0}\PY{p}{,} \PY{n}{tile\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{400}\PY{p}{,}
                            \PY{n}{show\PYZus{}gradient}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: Gradient min: -18.671440, max: 20.568424, stepsize:      3.32

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Gradient min: -11.179792, max:  9.536856, stepsize:      6.09

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Gradient min: -4.656498, max:  5.754077, stepsize:     11.15

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_7.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Gradient min: -2.704573, max:  2.700689, stepsize:     17.11

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_9.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Gradient min: -2.000956, max:  1.683443, stepsize:     24.70

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_11.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Gradient min: -1.683372, max:  1.462125, stepsize:     33.00

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_13.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Gradient min: -0.922037, max:  1.198139, stepsize:     42.23

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_15.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Gradient min: -0.769153, max:  1.201889, stepsize:     55.35

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_17.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Gradient min: -0.735602, max:  0.824792, stepsize:     65.39

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_19.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Gradient min: -0.762260, max:  0.433219, stepsize:     78.62

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_21.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]

Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_56_23.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    You can save the DeepDream image if you like.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{c+c1}{\PYZsh{} save\PYZus{}image(img\PYZus{}result, filename=\PYZsq{}deepdream\PYZus{}hulk.jpg\PYZsq{})}
\end{Verbatim}

    Now run the DeepDream algorithm recursively. We perform 5 recursive
steps (\texttt{num\_repeats+1}) where the image is blurred and
downscaled in each step and then the DeepDream algorithm is used on the
downscaled image. The resulting DeepDream image is then blended with the
original image in each step to add a little of the detail from the
original image. This is repeated a number of times.

Note how the DeepDream patterns are now larger. This is because the
patterns were first created on the low-resolution image and then refined
on the higher-resolution images.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}34}]:} \PY{n}{img\PYZus{}result} \PY{o}{=} \PY{n}{recursive\PYZus{}optimize}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{o}{=}\PY{n}{layer\PYZus{}tensor}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{n}{image}\PY{p}{,}
                          \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{3.0}\PY{p}{,} \PY{n}{rescale\PYZus{}factor}\PY{o}{=}\PY{l+m+mf}{0.7}\PY{p}{,}
                          \PY{n}{num\PYZus{}repeats}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{blend}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 0
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 1
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_7.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 2
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_9.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_11.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 3
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_13.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_15.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 4
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_17.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_60_19.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Now we will maximize a higher layer in the Inception model. In this case
it is layer number 7 (index 6). This layer recognizes more complex
shapes in the input image and the DeepDream algorithm will therefore
produce a more complex image. This layer appears to be recognizing
dog-faces and fur which the DeepDream algorithm has therefore added to
the image.

Note again that the colours of the input image are mostly retained as
opposed to other variants of the DeepDream algorithm which create more
pastel-like colours. This is because we are also smoothing the gradient
in the colour-channels so it becomes somewhat gray-scale and hence does
not change the colours of the input image so much.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{n}{layer\PYZus{}tensor} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{layer\PYZus{}tensors}\PY{p}{[}\PY{l+m+mi}{6}\PY{p}{]}
         \PY{n}{img\PYZus{}result} \PY{o}{=} \PY{n}{recursive\PYZus{}optimize}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{o}{=}\PY{n}{layer\PYZus{}tensor}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{n}{image}\PY{p}{,}
                          \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{3.0}\PY{p}{,} \PY{n}{rescale\PYZus{}factor}\PY{o}{=}\PY{l+m+mf}{0.7}\PY{p}{,}
                          \PY{n}{num\PYZus{}repeats}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{blend}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 0
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 1
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_7.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 2
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_9.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_11.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 3
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_13.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_15.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 4
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_17.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_62_19.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    This is an example of maximizing only a subset of a layer's
feature-channels using the DeepDream algorithm. In this case it is the
layer with index 7 and only its first 3 feature-channels that are
maximized.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{n}{layer\PYZus{}tensor} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{layer\PYZus{}tensors}\PY{p}{[}\PY{l+m+mi}{7}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{:}\PY{l+m+mi}{3}\PY{p}{]}
         \PY{n}{img\PYZus{}result} \PY{o}{=} \PY{n}{recursive\PYZus{}optimize}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{o}{=}\PY{n}{layer\PYZus{}tensor}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{n}{image}\PY{p}{,}
                          \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{3.0}\PY{p}{,} \PY{n}{rescale\PYZus{}factor}\PY{o}{=}\PY{l+m+mf}{0.7}\PY{p}{,}
                          \PY{n}{num\PYZus{}repeats}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{blend}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 0
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 1
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_7.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 2
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_9.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_11.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 3
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_13.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_15.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 4
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_17.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_64_19.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    This example shows the result of maximizing the first feature-channel of
the final layer in the Inception model. It is unclear what patterns this
layer and feature-channel might be recognizing in the input image.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}42}]:} \PY{n}{layer\PYZus{}tensor} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{layer\PYZus{}tensors}\PY{p}{[}\PY{l+m+mi}{11}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}
         \PY{n}{img\PYZus{}result} \PY{o}{=} \PY{n}{recursive\PYZus{}optimize}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{o}{=}\PY{n}{layer\PYZus{}tensor}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{n}{image}\PY{p}{,}
                          \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{3.0}\PY{p}{,} \PY{n}{rescale\PYZus{}factor}\PY{o}{=}\PY{l+m+mf}{0.7}\PY{p}{,}
                          \PY{n}{num\PYZus{}repeats}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{blend}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 0
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 1
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_7.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 2
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_9.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_11.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 3
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_13.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_15.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 4
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_17.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_66_19.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{escher}{%
\subsection{Escher}\label{escher}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{n}{image} \PY{o}{=} \PY{n}{load\PYZus{}image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{escher\PYZus{}planefilling2.jpg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plot\PYZus{}image}\PY{p}{(}\PY{n}{image}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_68_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{n}{layer\PYZus{}tensor} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{layer\PYZus{}tensors}\PY{p}{[}\PY{l+m+mi}{6}\PY{p}{]}
         \PY{n}{img\PYZus{}result} \PY{o}{=} \PY{n}{recursive\PYZus{}optimize}\PY{p}{(}\PY{n}{layer\PYZus{}tensor}\PY{o}{=}\PY{n}{layer\PYZus{}tensor}\PY{p}{,} \PY{n}{image}\PY{o}{=}\PY{n}{image}\PY{p}{,}
                          \PY{n}{num\PYZus{}iterations}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{step\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{3.0}\PY{p}{,} \PY{n}{rescale\PYZus{}factor}\PY{o}{=}\PY{l+m+mf}{0.7}\PY{p}{,}
                          \PY{n}{num\PYZus{}repeats}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{,} \PY{n}{blend}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 0
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 1
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_5.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_7.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 2
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_9.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_11.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 3
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_13.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_15.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Recursive level: 4
Image before:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_17.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Processing image: . . . . . . . . . . 
Image after:

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DeepDream_files/DeepDream_69_19.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{close-tensorflow-session}{%
\subsection{Close TensorFlow Session}\label{close-tensorflow-session}}

We are now done using TensorFlow, so we close the session to release its
resources.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}0}]:} \PY{c+c1}{\PYZsh{} This has been commented out in case you want to modify and experiment}
        \PY{c+c1}{\PYZsh{} with the Notebook without having to restart it.}
        \PY{c+c1}{\PYZsh{} session.close()}
\end{Verbatim}

    \hypertarget{conclusion}{%
\subsection{Conclusion}\label{conclusion}}

The deep dream methodology leads to some crazy images. But more
importantly it confirms our intuition on how neural networks break
images down with their hidden layers. Lower layers seem to capture
simple fundamental components of an image while the higher layers
capture complex objects. Using this tool we can see what exactly our
network learns and how it internalizes its goals.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
